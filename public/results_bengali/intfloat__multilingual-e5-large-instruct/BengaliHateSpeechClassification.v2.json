{
  "dataset_revision": "ccd942d16d2f0512799a1480034650a7b076027e",
  "task_name": "BengaliHateSpeechClassification.v2",
  "mteb_version": "2.3.11",
  "scores": {
    "test": [
      {
        " ": [
          {
            "accuracy": 0.555907,
            "f1": 0.450469,
            "f1_weighted": 0.557506,
            "precision": 0.477413,
            "precision_weighted": 0.606233,
            "recall": 0.496129,
            "recall_weighted": 0.555907,
            
          },
          {
            "accuracy": 0.682249,
            "f1": 0.604286,
            "f1_weighted": 0.681585,
            "precision": 0.599734,
            "precision_weighted": 0.689463,
            "recall": 0.623869,
            "recall_weighted": 0.682249,
            
          },
          {
            "accuracy": 0.6235,
            "f1": 0.530114,
            "f1_weighted": 0.612255,
            "precision": 0.576852,
            "precision_weighted": 0.648767,
            "recall": 0.551909,
            "recall_weighted": 0.6235,
            
          },
          {
            "accuracy": 0.635502,
            "f1": 0.540096,
            "f1_weighted": 0.623682,
            "precision": 0.566566,
            "precision_weighted": 0.628557,
            "recall": 0.529592,
            "recall_weighted": 0.635502,
            
          },
          {
            "accuracy": 0.603917,
            "f1": 0.508209,
            "f1_weighted": 0.600431,
            "precision": 0.555112,
            "precision_weighted": 0.650686,
            "recall": 0.54164,
            "recall_weighted": 0.603917,
            
          },
          {
            "accuracy": 0.641819,
            "f1": 0.56643,
            "f1_weighted": 0.650633,
            "precision": 0.583992,
            "precision_weighted": 0.674901,
            "recall": 0.578571,
            "recall_weighted": 0.641819,
            
          },
          {
            "accuracy": 0.60139,
            "f1": 0.520635,
            "f1_weighted": 0.611302,
            "precision": 0.526452,
            "precision_weighted": 0.630745,
            "recall": 0.523384,
            "recall_weighted": 0.60139,
            
          },
          {
            "accuracy": 0.629817,
            "f1": 0.550235,
            "f1_weighted": 0.624497,
            "precision": 0.578053,
            "precision_weighted": 0.641779,
            "recall": 0.558527,
            "recall_weighted": 0.629817,
            
          },
          {
            "accuracy": 0.581807,
            "f1": 0.511021,
            "f1_weighted": 0.585515,
            "precision": 0.530863,
            "precision_weighted": 0.608583,
            "recall": 0.526909,
            "recall_weighted": 0.581807,
            
          },
          {
            "accuracy": 0.618446,
            "f1": 0.537817,
            "f1_weighted": 0.626593,
            "precision": 0.551031,
            "precision_weighted": 0.658698,
            "recall": 0.563797,
            "recall_weighted": 0.618446,
            
          }
        ],
        "accuracy": 0.617435,
        "f1": 0.531931,
        "f1_weighted": 0.6174,
        "precision": 0.554607,
        "precision_weighted": 0.643841,
        "recall": 0.549433,
        "recall_weighted": 0.617435,
        "ap": NaN,
        "ap_weighted": NaN,
        "main_score": 0.531931
      }
    ]
  },
  "evaluation_time": 18.779433012008667,
  "kg_co2_emissions": null
}